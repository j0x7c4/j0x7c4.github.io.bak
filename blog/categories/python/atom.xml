<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | 醉過方知酒濃]]></title>
  <link href="http://j0x7c4.github.io/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://j0x7c4.github.io/"/>
  <updated>2014-04-22T02:47:19+08:00</updated>
  <id>http://j0x7c4.github.io/</id>
  <author>
    <name><![CDATA[Eli]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[用python写hive的UDAF]]></title>
    <link href="http://j0x7c4.github.io/blog/2014/01/05/hive-stream-with-python/"/>
    <updated>2014-01-05T15:33:00+08:00</updated>
    <id>http://j0x7c4.github.io/blog/2014/01/05/hive-stream-with-python</id>
    <content type="html"><![CDATA[<p>之前写过一篇关于说Python无法实现hive UDAF的文章，后来经过尝试，python完全可以代替JAVA实现hive中常用的UDF,UDAF,及UDTF.</p>

<p>通过<code>transform</code>语句，可以将hive语句中<code>select</code>得到的数据通过类似hadoop中<a href="http://hadoop.apache.org/docs/stable1/streaming.html">streaming</a>的方式，传给<code>using</code>语句中的脚本作为输入。用<code>DISTRIBUTE BY</code>将mapper的输出分类给reducer. </p>

<h2 id="udaf">UDAF</h2>

<p>由于<code>SELECT</code>和<code>DISTRIBUTE BY</code>是有先后顺序，所以要先得到经过<code>DISTRIBUTE BY</code>的数据，再用<code>TRANSFORM</code>进行转化，保证相同的key落入到同一个reducer中去。reducer把处理后的结果以<code>AS</code>中的字段格式进行输出。</p>

<p><code>
FROM (
SELECT a,b,c,d
FROM db
DISTRIBUTE BY a
SORT BY a,b ) T
SELECT TRANSFORM(T.a, T.b, T.c, T.d)
USING 'python udaf.py'
AS (a,b,e)
</code> </p>

<p>``` python
#! /usr/bin/env python
#encoding=utf-8
import sys
import logging</p>

<p>current={“a”:None,”b”:None,”e”:None}
a=None</p>

<p>def foo (c,d):
    e = ‘’
    #To-do, write something
    return e</p>

<p>def output ():
    #To-do, write something
    print …</p>

<p>for l in sys.stdin:
    try:
        a,b,c,d = l.strip().split(‘\t’)
        e=foo(c,d)
    except:
        logging.error(l)
        continue</p>

<pre><code>if current["a"] != a:
    if current["a"]: 
        output()
    current["a"]=a
    current["b"]=b
    current["e"]=e
else:
    current["e"]+=e
</code></pre>

<p>if current[“a”]:
    output()
```</p>

<h2 id="section">代码的重用</h2>

<p>如果按照以上的方式，是可以实现UDAF的效果，但是代码的重用性不高。如果在java中，可以写多个不同功能的类，然后打在一个jar包中。不过在python中实现起来有点困难，比如我在另一个py脚本中定义两个函数foo,bar,在一个udaf脚本中需要先import那个py 模块，然后再用这两个函数。这样就需要在<code>add file</code>中同时添加两个py脚本，在实际使用过程中，发现添加多个py脚本后，在py代码中使用import语句，会找不到那个文件的路径。原因是在hdfs中，这些py脚本不一定会在同一个目录下。所以只能把所有需要用到的函数写在同一个py脚本中。这样一来，以后需要同种功能的函数时，需要重写这些代码。之后再看看有没有其他可行的方案。</p>

<p><a href="/blog/2013/09/25/hive-python-udf/">HIVE中使用python实现UDF</a></p>

<p><a href="/blog/2013/11/01/udf-in-python-sucks/">在hive中使用python来做UDF有点糟</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在hive中使用python来做UDF有点糟]]></title>
    <link href="http://j0x7c4.github.io/blog/2013/11/01/udf-in-python-sucks/"/>
    <updated>2013-11-01T23:57:00+08:00</updated>
    <id>http://j0x7c4.github.io/blog/2013/11/01/udf-in-python-sucks</id>
    <content type="html"><![CDATA[<p>之前写了篇介绍如何在HIVE中用python来写UDF的文字，最近终于也开始需要用UDF来处理一些数据了。</p>

<p>可是现实和理想总是存在些差距，原本想着python简洁的代码和随改随用的特性，在UDF的灵活性上显得有点苍白无力。利用<code>TRANSFORM</code>, <code>USING</code>, <code>AS</code>的结构来把python的脚本当做UDF，虽然看起来非常方便，但实际用起来却有很大问题。</p>

<h2 id="section">无法单独处理某个字段</h2>
<p>没有仔细研究过这个具体的流程，不过猜想应该是从hive中select出来的数据以pipe的形式转到python的stdin中，再把python中的stdout的内容转到hive的输出中。这样如果仅需对选出的某个字段进行处理，其余字段不进行处理的话，必须在Python脚本中注意当前要处理的字段是第几个，一旦select中的顺序有所改变，那python脚本应该就无法处理了。目前仅选一个字段出来进行处理的情况比较少，大部分都是选出好几个字段来看。所以虽然python很好，不过我还是“十动然拒”了吧。</p>

<h2 id="section-1">无法外加聚集函数</h2>
<p>在使用中，下面这种格式是很死的。</p>

<p><code>sql
SELECT TRANSFORM(field_A, field_B) USING 'python foo.py' AS(field_AA, field_BB) FROM ...
</code></p>

<p>比如你想再对UDF外面加一层<code>Count</code>是没有办法实现的。某人会告诉你格式不对，无法运行。但是常规的用java写的UDF是没有问题的，全部都能hold住~</p>

<h2 id="section-2">外加的吐槽</h2>
<p>实际工作中，不仅仅需要<code>UDF</code>，<code>UDAF</code>和<code>UDTF</code>都是会经常遇到的。而Python拼死只能处理UDF的情况，对于后者只能呵呵了。于是反正UDAF和UDTF还是需要JAVA来写，那UDF也就顺便用JAVA写了吧。这样代码也统一一点，便于管理。</p>

<p>所以虽然python在UDF上的效果可以实现，不过功能太过简单，实际环境下还是很无力的。接下来还是用JAVA写<code>UDF</code>,<code>UDAF</code>和<code>UDTF</code>吧。回头吧，少年~</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[试用networkx]]></title>
    <link href="http://j0x7c4.github.io/blog/2013/10/16/try-networkx/"/>
    <updated>2013-10-16T01:44:00+08:00</updated>
    <id>http://j0x7c4.github.io/blog/2013/10/16/try-networkx</id>
    <content type="html"><![CDATA[<p>最近想用pagerank的方法来分析微博好友之间的权威关系，于是试着用crawler去抓微博上好友的信息，然后建立关系网络。在网上看到用networkx可以比较方便的建立关系网络，并且可以比较方便的用pagerank计算每个好友的重要性。</p>

<p>使用networks加入node和edge都很方便，并且networkx宣称他的node可以支持任何python的hashable的类型，于是我一开始使用custom的node.</p>

<p><code>python
class user:
    def __init__(self,args):
        assert re.search('^[\d]+$',args['uid'])
        self.uid = args['uid']
        self.info = args
    def __hash__(self):
        return int(self.uid)
</code></p>

<p>可是这样写并不正确，他好像对自定义的类支持不太好（或许是不支持自定义类）。于是在网上查了好久，才看到要实现给一个node添加附加信息的方法。</p>

<p><a href="http://stackoverflow.com/questions/8490794/how-do-i-make-a-cutomised-object-as-a-node-for-networkx-and-how-do-i-look-it-up">http://stackoverflow.com/questions/8490794/how-do-i-make-a-cutomised-object-as-a-node-for-networkx-and-how-do-i-look-it-up</a></p>

<p>于是在加入node的时候，应该用</p>

<p><code>python
G.add_node("label",foo="foo",bar="bar")
</code></p>

<p>于是把添加node改写成</p>

<p><code>python
G.add_node(user.uid,user.info)
</code></p>

<p>添加node和edge是没问题了，结果在保存<code>gml</code>文件时又出问题了，里面的字符串竟然不支持utf-8… 官方是这么解释的：
&gt;Notes</p>

<blockquote>
  <p>GML specifications indicate that the file should only use 7bit ASCII text encoding.iso8859-1 (latin-1).</p>
</blockquote>

<blockquote>
  <p>This implementation does not support all Python data types as GML data. Nodes, node attributes, edge attributes, and graph attributes must be either dictionaries or single stings or numbers. If they are not an attempt is made to represent them as strings. For example, a list as edge data G[1][2][‘somedata’]=[1,2,3], will be 
represented in the GML file as:</p>
</blockquote>

<blockquote>
  <p><a href="http://networkx.lanl.gov/reference/generated/networkx.readwrite.gml.write_gml.html">http://networkx.lanl.gov/reference/generated/networkx.readwrite.gml.write_gml.html</a></p>
</blockquote>

<p>于是我只好抽取是ascii的编码的用户信息。然后把类的定义改写成：</p>

<p><code>python
class user:
    def __init__(self,args):	
        assert re.search('^[\d]+$',args['uid'])
        self.uid = args['uid']
        self.info = {'uid':args['uid'],\
               'n_follows':args['n_follows'],\
                  'n_fans':args['n_fans'],\
                'n_weibos':args['n_weibos']}
    def __hash__(self):
        return int(self.uid)
</code></p>

<p>这样终于正常创建网络，读写gml文件了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenCV in Python]]></title>
    <link href="http://j0x7c4.github.io/blog/2013/07/20/opencv-in-python/"/>
    <updated>2013-07-20T00:00:00+08:00</updated>
    <id>http://j0x7c4.github.io/blog/2013/07/20/opencv-in-python</id>
    <content type="html"><![CDATA[<p>OpenCV基本上每個學Computer Vision都用過，我之前也是用C++來使用OpenCV, 最近為了處理一些圖片轉影片，加Marker之類的簡單的操作，懶得再用C++去寫。於是就嘗試用Python來寫OpenCV.</p>

<p>在Python中使用OpenCV, 只要把OpenCV的Library加到Python的Lib目錄下面就可以了。</p>

<p>具體就是把OpenCV目錄下的”build/python/2.7/cv2.pyd” 複製到Python的“Lib/site-packages”目錄中。</p>

<p>OpenCV被包在cv2这个module中，在一开始加载这个module就可以了。</p>

<p>OpenCV中经常会用到cv::Size, cv::Point, 在python中就用tuple来代替，不用再定义cv::Size或者cv::Point. 比如原来C++中定义一个size用cv::Size(640,480), 现在Python中直接用(640,480)来代替就好了。</p>

<p>下面这个例子就是把image_dir中的图片转换成avi格式的影片</p>

<p><code>python
import sys
import os
import cv2
import re
def intCmp ( x,y ):
	a = re.search('([\d]+).png',x).group(1)
	b = re.search('([\d]+).png',y).group(1)
	return int(a)-int(b)
if __name__ == '__main__':
	if len(sys.argv)&lt;3:
		print "Usage: %s (image_dir) (output)" %(sys.argv[0])
		exit(1)
	image_dir = sys.argv[1]
	output_file = sys.argv[2]
	image_list = sorted(os.listdir(image_dir),cmp=intCmp)
	video_writer = cv2.VideoWriter(output_file,-1,30,(640,480))
	for image_file in image_list:
		print image_file
		img = cv2.imread("%s/%s"%(image_dir,image_file.strip()))
		cv2.imshow("rgb",img)
		key = cv2.waitKey(10)
		video_writer.write(img)
		if key == 27:
			break;
</code></p>

<p>更多的细节可以看document</p>

<p><a href="http://docs.opencv.org/modules/refman.html">http://docs.opencv.org/modules/refman.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python urllib+json 与web API交互]]></title>
    <link href="http://j0x7c4.github.io/blog/2013/06/01/python-urllibjson-webAPI/"/>
    <updated>2013-06-01T00:00:00+08:00</updated>
    <id>http://j0x7c4.github.io/blog/2013/06/01/python-urllibjson-webAPI</id>
    <content type="html"><![CDATA[<p>目前的web app都流行用URL的方式传递Query, 然后接受server回传过来的json格式的结果。</p>

<p>利用python的urllib和json这两个模块，很容易就可以抓取里面的信息。</p>

<p><code>python
import json
import urllib
url=URL_QUERY
f = urllib.urlopen(url)
j = json.loads(f.read())
</code></p>

<p>f这个object存储了server回传的信息，通过<code>read()</code>将文字信息读出来。</p>

<p><code>loads()</code>将文字信息转成dictionary和list的形式，存储在j中。</p>
]]></content>
  </entry>
  
</feed>
